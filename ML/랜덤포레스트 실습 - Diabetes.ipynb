{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성: Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# export_graphviz: 나무 구조 생성 및 저장\n",
    "from sklearn.tree import export_graphviz\n",
    "# graphviz : 나무 구조 시각화 (.dot 확장자 파일 불러오기 등)\n",
    "import graphviz\n",
    "\n",
    "# 데이터 분할: train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# # 예측/회귀 Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 예측/회귀 Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>CHOLESTEROL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>HDL</th>\n",
       "      <th>TCH</th>\n",
       "      <th>LTG</th>\n",
       "      <th>GLUCOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>206</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y  AGE  GENDER   BMI     BP  CHOLESTEROL    LDL   HDL  TCH     LTG  \\\n",
       "0  151   59       2  32.1  101.0          157   93.2  38.0  4.0  4.8598   \n",
       "1   75   48       1  21.6   87.0          183  103.2  70.0  3.0  3.8918   \n",
       "2  141   72       2  30.5   93.0          156   93.6  41.0  4.0  4.6728   \n",
       "3  206   24       1  25.3   84.0          198  131.4  40.0  5.0  4.8903   \n",
       "4  135   50       1  23.0  101.0          192  125.4  52.0  4.0  4.2905   \n",
       "\n",
       "   GLUCOSE  \n",
       "0       87  \n",
       "1       69  \n",
       "2       85  \n",
       "3       89  \n",
       "4       80  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일명, 변수, 값 등에 한글 포함시 engine = \"python\"으로 지정\n",
    "df_raw= pd.read_csv(\"/home/pirl/test/BigData/DIABETES.csv\", encoding='euc-kr')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(X: 설명변수 데이터, Y: 목표변수 데이터, test_size = test 데이터 비율, random_state: randomseed)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(df_raw_x, df_raw_y\n",
    "                                                               , test_size = 0.3, random_state = 1234)\n",
    "print(\"train data X size : {}\".format(df_train_x.shape))\n",
    "print(\"train data Y size : {}\".format(df_train_y.shape))\n",
    "print(\"test data X size : {}\".format(df_test_x.shape))\n",
    "print(\"test data X size : {}\".format(df_test_y .shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_uncustomized = RandomForestRegressor(random_state = 1234)\n",
    "rf_uncustomized.fit(df_train_x, df_train_y)\n",
    "# Train 데이터 설명력\n",
    "print(\"Score on training set: {:.3f}\".format(rf_uncustomized.score(df_train_x, df_train_y)))\n",
    "# Test 데이터 설명력\n",
    "print(\"Score on test set: {:.3f}\".format(rf_uncustomized.score(df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 설명력 결과 저장\n",
    "train_score = []; test_score = []\n",
    "# n_estimators: 트리 수 변경: 1~100\n",
    "para_n_tree = [n_tree * 10 for n_tree in range(1,21)] #참조: para_n_tree: [10,20,30,...,100]\n",
    "\n",
    "for v_n_estimators in para_n_tree:\n",
    "    rf = RandomForestRegressor(n_estimators=v_n_estimators, random_state = 1234)\n",
    "    rf.fit(df_train_x, df_train_y)\n",
    "    train_score.append(rf.score(df_train_x, df_train_y))\n",
    "    test_score.append(rf.score(df_test_x, df_test_y))\n",
    "    \n",
    "# 결과 저장\n",
    "df_score_leaf = pd.DataFrame()\n",
    "df_score_leaf[\"n_estimators\"] = para_n_tree\n",
    "df_score_leaf[\"TrainScore\"] = train_score\n",
    "df_score_leaf[\"TestScore\"] = test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 확인\n",
    "df_score_leaf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_n_tree, train_score, linestyle = \"-\", label = \"Train Score\")\n",
    "plt.plot(para_n_tree, test_score, linestyle = \"--\", label = \"Test Score\")\n",
    "plt.ylabel(\"score\"); plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "생성하는 결정 트리 수 증가에 따라 모델의 설명력은 증가하며\n",
    "트리 수가 30개를 초과해도 설명력은 거의 향상되지 않음\n",
    "최대 트리 수에 따른 영향을 배제하고 다른 파라미터의 영향을 확인하고자 150 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 설명력 결과 저장\n",
    "train_score = []; test_score = []\n",
    "# min_samples_leaf: 잎사귀 최소 자료 수\n",
    "para_leaf = [n_leaf * 1 for n_leaf in range(1,21)] #참조: para_leaf: [1,2,3,...,20]\n",
    "\n",
    "for v_min_samples_leaf in para_leaf:\n",
    "    rf = RandomForestRegressor(random_state = 1234, n_estimators = 150,\n",
    "                               min_samples_leaf = v_min_samples_leaf)\n",
    "    rf.fit(df_train_x, df_train_y)\n",
    "    train_score.append(rf.score(df_train_x, df_train_y))\n",
    "    test_score.append(rf.score(df_test_x, df_test_y))\n",
    "      \n",
    "# 결과 저장\n",
    "df_score_leaf = pd.DataFrame()\n",
    "df_score_leaf[\"MinSamplesLeaf\"] = para_leaf\n",
    "df_score_leaf[\"TrainScore\"] = train_score\n",
    "df_score_leaf[\"TestScore\"] = test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 확인\n",
    "df_score_leaf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_leaf, train_score, linestyle = \"-\", label = \"Train Score\")\n",
    "plt.plot(para_leaf, test_score, linestyle = \"--\", label = \"Test Score\")\n",
    "plt.ylabel(\"score\"); plt.xlabel(\"min samples leaf\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "잎사귀 노드의 최소 자료 수 증가에 따라 모델의 설명력은 감소하며\n",
    "test 데이터의 정확도 변화를 고려하여 8 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 설명력 결과 저장\n",
    "train_score = []; test_score = []\n",
    "# min_samples_leaf: 잎사귀 최소 자료 수\n",
    "para_split = [n_split * 2 for n_split in range(2,30)] #참조: para_leaf: [4,6,8,...,40]\n",
    "\n",
    "for v_min_samples_split in para_split:\n",
    "    rf = RandomForestRegressor(random_state = 1234, n_estimators = 150, min_samples_leaf = 8,\n",
    "                               min_samples_split = v_min_samples_split)\n",
    "    rf.fit(df_train_x, df_train_y)\n",
    "    train_score.append(rf.score(df_train_x, df_train_y))\n",
    "    test_score.append(rf.score(df_test_x, df_test_y))\n",
    "      \n",
    "# 결과 저장\n",
    "df_score_split = pd.DataFrame()\n",
    "df_score_split[\"MinSamplesSplit\"] = para_split\n",
    "df_score_split[\"TrainScore\"] = train_score\n",
    "df_score_split[\"TestScore\"] = test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 확인\n",
    "df_score_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_split, train_score, linestyle = \"-\", label = \"Train Score\")\n",
    "plt.plot(para_split, test_score, linestyle = \"--\", label = \"Test Score\")\n",
    "plt.ylabel(\"score\"); plt.xlabel(\"min samples leaf\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "분리 노드 최소 자료 수 증가에 따라 모델의 설명력은 감소하며\n",
    "Train/test 데이터의 성능변화를 고려하여 20선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 설명력 결과 저장\n",
    "train_score = []; test_score = []\n",
    "# max_depth: 최대 깊이 변경\n",
    "para_depth = [n_depth for n_depth in range(1,11)] \n",
    "\n",
    "for v_max_depth in para_depth:\n",
    "    rf = RandomForestRegressor(random_state = 1234, n_estimators = 150, \n",
    "                               min_samples_leaf = 8, min_samples_split = 20,\n",
    "                               max_depth = v_max_depth)\n",
    "    rf.fit(df_train_x, df_train_y)\n",
    "    train_score.append(rf.score(df_train_x, df_train_y))\n",
    "    test_score.append(rf.score(df_test_x, df_test_y))\n",
    "      \n",
    "# 결과 저장\n",
    "df_score_split = pd.DataFrame()\n",
    "df_score_split[\"Depth\"] = para_depth\n",
    "df_score_split[\"TrainScore\"] = train_score\n",
    "df_score_split[\"TestScore\"] = test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 확인\n",
    "df_score_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_depth, train_score, linestyle = \"-\", label = \"Train Score\")\n",
    "plt.plot(para_depth, test_score, linestyle = \"--\", label = \"Test Score\")\n",
    "plt.ylabel(\"score\"); plt.xlabel(\"min samples leaf\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "최대 깊이 증가에 따라 모델의 설명력은 증가하며\n",
    "Train/test 데이터의 정확도 변화를 고려하여 5 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 깊이 = 2 모델\n",
    "rf_final = RandomForestRegressor(random_state = 1234, n_estimators = 150, min_samples_leaf = 8, \n",
    "                                 min_samples_split = 20, max_depth = 5)\n",
    "\n",
    "rf_final.fit(df_train_x, df_train_y)\n",
    "\n",
    "# Train 데이터 설명력\n",
    "print(\"Score on training set: {:.3f}\".format(rf_final.score(df_train_x, df_train_y)))\n",
    "# Test 데이터 설명력\n",
    "print(\"Score on test set: {:.3f}\".format(rf_final.score(df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 저장\n",
    "v_feature_name = df_train_x.columns\n",
    "# 0번 트리\n",
    "export_graphviz(rf_final.estimators_[0], out_file = \"rfr_final_0.dot\",feature_names= v_feature_name, impurity=True, filled=True)\n",
    "\n",
    "# tree_final_0.dot 그리기\n",
    "with open(\"rfr_final_0.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번 트리\n",
    "export_graphviz(rf_final.estimators_[1], out_file = \"rfr_final_1.dot\",feature_names= v_feature_name, impurity=True, filled=True)\n",
    "\n",
    "# tree_final_0.dot 그리기\n",
    "with open(\"rfr_final_1.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 데이블 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = rf_final.feature_importances_\n",
    "\n",
    "# feature_importances의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "df_importance.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# 중요도가 높은 변수를 상위에 그림\n",
    "df_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "coordinates = range(len(df_importance))\n",
    "plt.barh(y = coordinates, width = df_importance[\"Importance\"])\n",
    "plt.yticks(coordinates, df_importance[\"Feature\"])\n",
    "plt.xlabel(\"변수 중요도\")\n",
    "plt.ylabel(\"변수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(random_state = 1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"max_depth\": para_depth, \"min_samples_split\": para_split, \"min_samples_leaf\": para_leaf}\n",
    "\n",
    "# 설명력이 높은 최적 parameter 찾기\n",
    "grid_dt = GridSearchCV(estimator, param_grid, scoring = \"r2\", n_jobs = -1)\n",
    "grid_dt.fit(df_train_x, df_train_y)\n",
    "\n",
    "print(\"best estimator model: \\n{}\".format(grid_dt.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_dt.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_dt.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
